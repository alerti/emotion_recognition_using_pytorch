{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class SeparableConv2d(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False):\n",
    "        super(SeparableConv2d, self).__init__()\n",
    "        self.depthwise = nn.Conv2d(in_channels, in_channels, kernel_size, stride, padding, dilation, groups=in_channels,\n",
    "                                   bias=bias)\n",
    "        self.pointwise = nn.Conv2d(in_channels, out_channels, 1, 1, 0, 1, 1, bias=bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.depthwise(x)\n",
    "        x = self.pointwise(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channeld, out_channels):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "\n",
    "        self.residual_conv = nn.Conv2d(in_channels=in_channeld, out_channels=out_channels, kernel_size=1, stride=2,\n",
    "                                       bias=False)\n",
    "        self.residual_bn = nn.BatchNorm2d(out_channels, momentum=0.99, eps=1e-3)\n",
    "\n",
    "        self.sepConv1 = SeparableConv2d(in_channels=in_channeld, out_channels=out_channels, kernel_size=3, bias=False,\n",
    "                                        padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels, momentum=0.99, eps=1e-3)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.sepConv2 = SeparableConv2d(in_channels=out_channels, out_channels=out_channels, kernel_size=3, bias=False,\n",
    "                                        padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels, momentum=0.99, eps=1e-3)\n",
    "        self.maxp = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        res = self.residual_conv(x)\n",
    "        res = self.residual_bn(res)\n",
    "        x = self.sepConv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.sepConv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.maxp(x)\n",
    "        return res + x\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=8, kernel_size=3, stride=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(8, affine=True, momentum=0.99, eps=1e-3)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(in_channels=8, out_channels=8, kernel_size=3, stride=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(8, momentum=0.99, eps=1e-3)\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "        self.module1 = ResidualBlock(in_channeld=8, out_channels=16)\n",
    "        self.module2 = ResidualBlock(in_channeld=16, out_channels=32)\n",
    "        self.module3 = ResidualBlock(in_channeld=32, out_channels=64)\n",
    "        self.module4 = ResidualBlock(in_channeld=64, out_channels=128)\n",
    "\n",
    "        self.last_conv = nn.Conv2d(in_channels=128, out_channels=num_classes, kernel_size=3, padding=1)\n",
    "        self.avgp = nn.AdaptiveAvgPool2d((1, 1))\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = input\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.module1(x)\n",
    "        x = self.module2(x)\n",
    "        x = self.module3(x)\n",
    "        x = self.module4(x)\n",
    "        x = self.last_conv(x)\n",
    "        x = self.avgp(x)\n",
    "        x = x.view((x.shape[0], -1))\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Conv2d: 1-1                            [-1, 8, 42, 42]           72\n",
      "├─BatchNorm2d: 1-2                       [-1, 8, 42, 42]           16\n",
      "├─ReLU: 1-3                              [-1, 8, 42, 42]           --\n",
      "├─Conv2d: 1-4                            [-1, 8, 40, 40]           576\n",
      "├─BatchNorm2d: 1-5                       [-1, 8, 40, 40]           16\n",
      "├─ReLU: 1-6                              [-1, 8, 40, 40]           --\n",
      "├─ResidualBlock: 1-7                     [-1, 16, 20, 20]          --\n",
      "|    └─Conv2d: 2-1                       [-1, 16, 20, 20]          128\n",
      "|    └─BatchNorm2d: 2-2                  [-1, 16, 20, 20]          32\n",
      "|    └─SeparableConv2d: 2-3              [-1, 16, 40, 40]          --\n",
      "|    |    └─Conv2d: 3-1                  [-1, 8, 40, 40]           72\n",
      "|    |    └─Conv2d: 3-2                  [-1, 16, 40, 40]          128\n",
      "|    └─BatchNorm2d: 2-4                  [-1, 16, 40, 40]          32\n",
      "|    └─ReLU: 2-5                         [-1, 16, 40, 40]          --\n",
      "|    └─SeparableConv2d: 2-6              [-1, 16, 40, 40]          --\n",
      "|    |    └─Conv2d: 3-3                  [-1, 16, 40, 40]          144\n",
      "|    |    └─Conv2d: 3-4                  [-1, 16, 40, 40]          256\n",
      "|    └─BatchNorm2d: 2-7                  [-1, 16, 40, 40]          32\n",
      "|    └─MaxPool2d: 2-8                    [-1, 16, 20, 20]          --\n",
      "├─ResidualBlock: 1-8                     [-1, 32, 10, 10]          --\n",
      "|    └─Conv2d: 2-9                       [-1, 32, 10, 10]          512\n",
      "|    └─BatchNorm2d: 2-10                 [-1, 32, 10, 10]          64\n",
      "|    └─SeparableConv2d: 2-11             [-1, 32, 20, 20]          --\n",
      "|    |    └─Conv2d: 3-5                  [-1, 16, 20, 20]          144\n",
      "|    |    └─Conv2d: 3-6                  [-1, 32, 20, 20]          512\n",
      "|    └─BatchNorm2d: 2-12                 [-1, 32, 20, 20]          64\n",
      "|    └─ReLU: 2-13                        [-1, 32, 20, 20]          --\n",
      "|    └─SeparableConv2d: 2-14             [-1, 32, 20, 20]          --\n",
      "|    |    └─Conv2d: 3-7                  [-1, 32, 20, 20]          288\n",
      "|    |    └─Conv2d: 3-8                  [-1, 32, 20, 20]          1,024\n",
      "|    └─BatchNorm2d: 2-15                 [-1, 32, 20, 20]          64\n",
      "|    └─MaxPool2d: 2-16                   [-1, 32, 10, 10]          --\n",
      "├─ResidualBlock: 1-9                     [-1, 64, 5, 5]            --\n",
      "|    └─Conv2d: 2-17                      [-1, 64, 5, 5]            2,048\n",
      "|    └─BatchNorm2d: 2-18                 [-1, 64, 5, 5]            128\n",
      "|    └─SeparableConv2d: 2-19             [-1, 64, 10, 10]          --\n",
      "|    |    └─Conv2d: 3-9                  [-1, 32, 10, 10]          288\n",
      "|    |    └─Conv2d: 3-10                 [-1, 64, 10, 10]          2,048\n",
      "|    └─BatchNorm2d: 2-20                 [-1, 64, 10, 10]          128\n",
      "|    └─ReLU: 2-21                        [-1, 64, 10, 10]          --\n",
      "|    └─SeparableConv2d: 2-22             [-1, 64, 10, 10]          --\n",
      "|    |    └─Conv2d: 3-11                 [-1, 64, 10, 10]          576\n",
      "|    |    └─Conv2d: 3-12                 [-1, 64, 10, 10]          4,096\n",
      "|    └─BatchNorm2d: 2-23                 [-1, 64, 10, 10]          128\n",
      "|    └─MaxPool2d: 2-24                   [-1, 64, 5, 5]            --\n",
      "├─ResidualBlock: 1-10                    [-1, 128, 3, 3]           --\n",
      "|    └─Conv2d: 2-25                      [-1, 128, 3, 3]           8,192\n",
      "|    └─BatchNorm2d: 2-26                 [-1, 128, 3, 3]           256\n",
      "|    └─SeparableConv2d: 2-27             [-1, 128, 5, 5]           --\n",
      "|    |    └─Conv2d: 3-13                 [-1, 64, 5, 5]            576\n",
      "|    |    └─Conv2d: 3-14                 [-1, 128, 5, 5]           8,192\n",
      "|    └─BatchNorm2d: 2-28                 [-1, 128, 5, 5]           256\n",
      "|    └─ReLU: 2-29                        [-1, 128, 5, 5]           --\n",
      "|    └─SeparableConv2d: 2-30             [-1, 128, 5, 5]           --\n",
      "|    |    └─Conv2d: 3-15                 [-1, 128, 5, 5]           1,152\n",
      "|    |    └─Conv2d: 3-16                 [-1, 128, 5, 5]           16,384\n",
      "|    └─BatchNorm2d: 2-31                 [-1, 128, 5, 5]           256\n",
      "|    └─MaxPool2d: 2-32                   [-1, 128, 3, 3]           --\n",
      "├─Conv2d: 1-11                           [-1, 7, 3, 3]             8,071\n",
      "├─AdaptiveAvgPool2d: 1-12                [-1, 7, 1, 1]             --\n",
      "==========================================================================================\n",
      "Total params: 56,951\n",
      "Trainable params: 56,951\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 4.54\n",
      "------------------------------------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 2.61\n",
      "Params size (MB): 0.22\n",
      "Estimated Total Size (MB): 2.84\n",
      "------------------------------------------------------------------------------------------\n",
      "training size 28709 : private val size 3589 : public val size 3589\n",
      "learning_rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/alerti/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/alerti/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/alerti/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/alerti/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-cfc94f2518c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-cfc94f2518c1>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0my_predicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_predicted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_predicted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import csv\n",
    "from PIL import Image\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "if not torch.cuda.is_available():\n",
    "    from torchsummary import summary\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "shape = (44, 44)\n",
    "\n",
    "\n",
    "class DataSetFactory:\n",
    "\n",
    "    def __init__(self):\n",
    "        images = []\n",
    "        emotions = []\n",
    "        private_images = []\n",
    "        private_emotions = []\n",
    "        public_images = []\n",
    "        public_emotions = []\n",
    "\n",
    "        with open('../dataset/fer2013.csv', 'r') as csvin:\n",
    "            data = csv.reader(csvin)\n",
    "            next(data)\n",
    "            for row in data:\n",
    "                face = [int(pixel) for pixel in row[1].split()]\n",
    "                face = np.asarray(face).reshape(48, 48)\n",
    "                face = face.astype('uint8')\n",
    "\n",
    "                if row[-1] == 'Training':\n",
    "                    emotions.append(int(row[0]))\n",
    "                    images.append(Image.fromarray(face))\n",
    "                elif row[-1] == \"PrivateTest\":\n",
    "                    private_emotions.append(int(row[0]))\n",
    "                    private_images.append(Image.fromarray(face))\n",
    "                elif row[-1] == \"PublicTest\":\n",
    "                    public_emotions.append(int(row[0]))\n",
    "                    public_images.append(Image.fromarray(face))\n",
    "\n",
    "        print('training size %d : private val size %d : public val size %d' % (\n",
    "            len(images), len(private_images), len(public_images)))\n",
    "        train_transform = transforms.Compose([\n",
    "            transforms.RandomCrop(shape[0]),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            ToTensor(),\n",
    "        ])\n",
    "        val_transform = transforms.Compose([\n",
    "            transforms.CenterCrop(shape[0]),\n",
    "            ToTensor(),\n",
    "        ])\n",
    "\n",
    "        self.training = DataSet(transform=train_transform, images=images, emotions=emotions)\n",
    "        self.private = DataSet(transform=val_transform, images=private_images, emotions=private_emotions)\n",
    "        self.public = DataSet(transform=val_transform, images=public_images, emotions=public_emotions)\n",
    "\n",
    "\n",
    "class DataSet(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, transform=None, images=None, emotions=None):\n",
    "        self.transform = transform\n",
    "        self.images = images\n",
    "        self.emotions = emotions\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = self.images[index]\n",
    "        emotion = self.emotions[index]\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        return image, emotion\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "\n",
    "def main():\n",
    "    # variables  -------------\n",
    "    batch_size = 128\n",
    "    lr = 0.01\n",
    "    epochs = 100\n",
    "    learning_rate_decay_start = 80\n",
    "    learning_rate_decay_every = 5\n",
    "    learning_rate_decay_rate = 0.9\n",
    "    # ------------------------\n",
    "\n",
    "    classes = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
    "    network = model.Model(num_classes=len(classes)).to(device)\n",
    "    if not torch.cuda.is_available():\n",
    "        summary(network, (1, shape[0], shape[1]))\n",
    "\n",
    "    optimizer = torch.optim.SGD(network.parameters(), lr=lr, momentum=0.9, weight_decay=5e-3)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    factory = DataSetFactory()\n",
    "\n",
    "    training_loader = DataLoader(factory.training, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "    validation_loader = {\n",
    "        'private': DataLoader(factory.private, batch_size=batch_size, shuffle=True, num_workers=1),\n",
    "        'public': DataLoader(factory.public, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "    }\n",
    "\n",
    "    min_validation_loss = {\n",
    "        'private': 10000,\n",
    "        'public': 10000,\n",
    "    }\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        network.train()\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        total_train_loss = 0\n",
    "        if epoch > learning_rate_decay_start and learning_rate_decay_start >= 0:\n",
    "\n",
    "            #\n",
    "            frac = (epoch - learning_rate_decay_start) // learning_rate_decay_every\n",
    "            decay_factor = learning_rate_decay_rate ** frac\n",
    "            current_lr = lr * decay_factor\n",
    "            for group in optimizer.param_groups:\n",
    "                group['lr'] = current_lr\n",
    "        else:\n",
    "            current_lr = lr\n",
    "\n",
    "        print('learning_rate: %s' % str(current_lr))\n",
    "        for i, (x_train, y_train) in enumerate(training_loader):\n",
    "            optimizer.zero_grad()\n",
    "            x_train = x_train.to(device)\n",
    "            y_train = y_train.to(device)\n",
    "            y_predicted = network(x_train)\n",
    "            loss = criterion(y_predicted, y_train)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            _, predicted = torch.max(y_predicted.data, 1)\n",
    "            total_train_loss += loss.data\n",
    "            total += y_train.size(0)\n",
    "            correct += predicted.eq(y_train.data).sum()\n",
    "        accuracy = 100. * float(correct) / total\n",
    "        print('Epoch [%d/%d] Training Loss: %.4f, Accuracy: %.4f' % (\n",
    "            epoch + 1, epochs, total_train_loss / (i + 1), accuracy))\n",
    "\n",
    "        network.eval()\n",
    "        with torch.no_grad():\n",
    "            for name in ['private', 'public']:\n",
    "                total = 0\n",
    "                correct = 0\n",
    "                total_validation_loss = 0\n",
    "                for j, (x_val, y_val) in enumerate(validation_loader[name]):\n",
    "                    x_val = x_val.to(device)\n",
    "                    y_val = y_val.to(device)\n",
    "                    y_val_predicted = network(x_val)\n",
    "                    val_loss = criterion(y_val_predicted, y_val)\n",
    "                    _, predicted = torch.max(y_val_predicted.data, 1)\n",
    "                    total_validation_loss += val_loss.data\n",
    "                    total += y_val.size(0)\n",
    "                    correct += predicted.eq(y_val.data).sum()\n",
    "\n",
    "                accuracy = 100. * float(correct) / total\n",
    "                if total_validation_loss <= min_validation_loss[name]:\n",
    "                    if epoch >= 10:\n",
    "                        print('saving new model')\n",
    "                        state = {'net': network.state_dict()}\n",
    "                        torch.save(state, '../trained/%s_model_%d_%d.t7' % (name, epoch + 1, accuracy))\n",
    "                    min_validation_loss[name] = total_validation_loss\n",
    "\n",
    "                print('Epoch [%d/%d] %s validation Loss: %.4f, Accuracy: %.4f' % (\n",
    "                    epoch + 1, epochs, name, total_validation_loss / (j + 1), accuracy))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Conv2d: 1-1                            [-1, 8, 46, 46]           72\n",
      "├─BatchNorm2d: 1-2                       [-1, 8, 46, 46]           16\n",
      "├─ReLU: 1-3                              [-1, 8, 46, 46]           --\n",
      "├─Conv2d: 1-4                            [-1, 8, 44, 44]           576\n",
      "├─BatchNorm2d: 1-5                       [-1, 8, 44, 44]           16\n",
      "├─ReLU: 1-6                              [-1, 8, 44, 44]           --\n",
      "├─ResidualBlock: 1-7                     [-1, 16, 22, 22]          --\n",
      "|    └─Conv2d: 2-1                       [-1, 16, 22, 22]          128\n",
      "|    └─BatchNorm2d: 2-2                  [-1, 16, 22, 22]          32\n",
      "|    └─SeparableConv2d: 2-3              [-1, 16, 44, 44]          --\n",
      "|    |    └─Conv2d: 3-1                  [-1, 8, 44, 44]           72\n",
      "|    |    └─Conv2d: 3-2                  [-1, 16, 44, 44]          128\n",
      "|    └─BatchNorm2d: 2-4                  [-1, 16, 44, 44]          32\n",
      "|    └─ReLU: 2-5                         [-1, 16, 44, 44]          --\n",
      "|    └─SeparableConv2d: 2-6              [-1, 16, 44, 44]          --\n",
      "|    |    └─Conv2d: 3-3                  [-1, 16, 44, 44]          144\n",
      "|    |    └─Conv2d: 3-4                  [-1, 16, 44, 44]          256\n",
      "|    └─BatchNorm2d: 2-7                  [-1, 16, 44, 44]          32\n",
      "|    └─MaxPool2d: 2-8                    [-1, 16, 22, 22]          --\n",
      "├─ResidualBlock: 1-8                     [-1, 32, 11, 11]          --\n",
      "|    └─Conv2d: 2-9                       [-1, 32, 11, 11]          512\n",
      "|    └─BatchNorm2d: 2-10                 [-1, 32, 11, 11]          64\n",
      "|    └─SeparableConv2d: 2-11             [-1, 32, 22, 22]          --\n",
      "|    |    └─Conv2d: 3-5                  [-1, 16, 22, 22]          144\n",
      "|    |    └─Conv2d: 3-6                  [-1, 32, 22, 22]          512\n",
      "|    └─BatchNorm2d: 2-12                 [-1, 32, 22, 22]          64\n",
      "|    └─ReLU: 2-13                        [-1, 32, 22, 22]          --\n",
      "|    └─SeparableConv2d: 2-14             [-1, 32, 22, 22]          --\n",
      "|    |    └─Conv2d: 3-7                  [-1, 32, 22, 22]          288\n",
      "|    |    └─Conv2d: 3-8                  [-1, 32, 22, 22]          1,024\n",
      "|    └─BatchNorm2d: 2-15                 [-1, 32, 22, 22]          64\n",
      "|    └─MaxPool2d: 2-16                   [-1, 32, 11, 11]          --\n",
      "├─ResidualBlock: 1-9                     [-1, 64, 6, 6]            --\n",
      "|    └─Conv2d: 2-17                      [-1, 64, 6, 6]            2,048\n",
      "|    └─BatchNorm2d: 2-18                 [-1, 64, 6, 6]            128\n",
      "|    └─SeparableConv2d: 2-19             [-1, 64, 11, 11]          --\n",
      "|    |    └─Conv2d: 3-9                  [-1, 32, 11, 11]          288\n",
      "|    |    └─Conv2d: 3-10                 [-1, 64, 11, 11]          2,048\n",
      "|    └─BatchNorm2d: 2-20                 [-1, 64, 11, 11]          128\n",
      "|    └─ReLU: 2-21                        [-1, 64, 11, 11]          --\n",
      "|    └─SeparableConv2d: 2-22             [-1, 64, 11, 11]          --\n",
      "|    |    └─Conv2d: 3-11                 [-1, 64, 11, 11]          576\n",
      "|    |    └─Conv2d: 3-12                 [-1, 64, 11, 11]          4,096\n",
      "|    └─BatchNorm2d: 2-23                 [-1, 64, 11, 11]          128\n",
      "|    └─MaxPool2d: 2-24                   [-1, 64, 6, 6]            --\n",
      "├─ResidualBlock: 1-10                    [-1, 128, 3, 3]           --\n",
      "|    └─Conv2d: 2-25                      [-1, 128, 3, 3]           8,192\n",
      "|    └─BatchNorm2d: 2-26                 [-1, 128, 3, 3]           256\n",
      "|    └─SeparableConv2d: 2-27             [-1, 128, 6, 6]           --\n",
      "|    |    └─Conv2d: 3-13                 [-1, 64, 6, 6]            576\n",
      "|    |    └─Conv2d: 3-14                 [-1, 128, 6, 6]           8,192\n",
      "|    └─BatchNorm2d: 2-28                 [-1, 128, 6, 6]           256\n",
      "|    └─ReLU: 2-29                        [-1, 128, 6, 6]           --\n",
      "|    └─SeparableConv2d: 2-30             [-1, 128, 6, 6]           --\n",
      "|    |    └─Conv2d: 3-15                 [-1, 128, 6, 6]           1,152\n",
      "|    |    └─Conv2d: 3-16                 [-1, 128, 6, 6]           16,384\n",
      "|    └─BatchNorm2d: 2-31                 [-1, 128, 6, 6]           256\n",
      "|    └─MaxPool2d: 2-32                   [-1, 128, 3, 3]           --\n",
      "├─Conv2d: 1-11                           [-1, 7, 3, 3]             8,071\n",
      "├─AdaptiveAvgPool2d: 1-12                [-1, 7, 1, 1]             --\n",
      "==========================================================================================\n",
      "Total params: 56,951\n",
      "Trainable params: 56,951\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 5.60\n",
      "------------------------------------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 3.19\n",
      "Params size (MB): 0.22\n",
      "Estimated Total Size (MB): 3.42\n",
      "------------------------------------------------------------------------------------------\n",
      "../test/angry.jpg Angry tensor([99.7067])\n",
      "../test/happy.jpg Happy tensor([93.7929])\n",
      "../test/sad.jpg Sad tensor([91.2574])\n",
      "../test/surprised.jpg Surprised tensor([97.9845])\n",
      "[array([[[242, 242, 242],\n",
      "        [245, 245, 245],\n",
      "        [238, 238, 239],\n",
      "        ...,\n",
      "        [  5,   5,   5],\n",
      "        [  5,   5,   5],\n",
      "        [  5,   5,   5]],\n",
      "\n",
      "       [[241, 241, 242],\n",
      "        [237, 239, 241],\n",
      "        [231, 236, 241],\n",
      "        ...,\n",
      "        [  5,   5,   5],\n",
      "        [  5,   5,   5],\n",
      "        [  5,   5,   5]],\n",
      "\n",
      "       [[243, 244, 244],\n",
      "        [238, 241, 245],\n",
      "        [234, 242, 248],\n",
      "        ...,\n",
      "        [  5,   5,   5],\n",
      "        [  5,   5,   5],\n",
      "        [  5,   5,   5]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[245, 245, 245],\n",
      "        [235, 235, 235],\n",
      "        [244, 244, 244],\n",
      "        ...,\n",
      "        [ 75,  75,  75],\n",
      "        [ 75,  75,  75],\n",
      "        [ 75,  75,  75]],\n",
      "\n",
      "       [[220, 215, 216],\n",
      "        [100,  96,  97],\n",
      "        [ 68,  63,  64],\n",
      "        ...,\n",
      "        [ 75,  75,  75],\n",
      "        [ 75,  75,  75],\n",
      "        [ 75,  75,  75]],\n",
      "\n",
      "       [[ 59,  53,  54],\n",
      "        [ 53,  47,  48],\n",
      "        [ 65,  59,  60],\n",
      "        ...,\n",
      "        [ 75,  75,  75],\n",
      "        [ 75,  75,  75],\n",
      "        [ 75,  75,  75]]], dtype=uint8), array([[[231, 224, 215],\n",
      "        [225, 216, 213],\n",
      "        [132, 127, 128],\n",
      "        ...,\n",
      "        [ 37,  37,  37],\n",
      "        [ 37,  37,  37],\n",
      "        [ 37,  37,  37]],\n",
      "\n",
      "       [[231, 224, 215],\n",
      "        [229, 220, 217],\n",
      "        [129, 129, 129],\n",
      "        ...,\n",
      "        [ 37,  37,  37],\n",
      "        [ 37,  37,  37],\n",
      "        [ 37,  37,  37]],\n",
      "\n",
      "       [[230, 223, 214],\n",
      "        [206, 203, 199],\n",
      "        [121, 123, 123],\n",
      "        ...,\n",
      "        [ 37,  37,  37],\n",
      "        [ 37,  37,  37],\n",
      "        [ 37,  37,  37]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 70,  79,  88],\n",
      "        [ 73,  85,  91],\n",
      "        [ 53,  62,  71],\n",
      "        ...,\n",
      "        [ 77,  77,  77],\n",
      "        [ 78,  78,  78],\n",
      "        [ 78,  78,  78]],\n",
      "\n",
      "       [[ 62,  74,  74],\n",
      "        [ 67,  76,  85],\n",
      "        [ 53,  61,  71],\n",
      "        ...,\n",
      "        [ 78,  78,  78],\n",
      "        [ 78,  78,  78],\n",
      "        [ 78,  78,  78]],\n",
      "\n",
      "       [[ 51,  63,  63],\n",
      "        [ 65,  75,  83],\n",
      "        [ 52,  62,  69],\n",
      "        ...,\n",
      "        [ 78,  78,  78],\n",
      "        [ 78,  78,  78],\n",
      "        [ 78,  78,  78]]], dtype=uint8), array([[[140, 183, 186],\n",
      "        [153, 183, 188],\n",
      "        [143, 157, 162],\n",
      "        ...,\n",
      "        [ 58,  58,  58],\n",
      "        [ 58,  58,  58],\n",
      "        [ 58,  58,  58]],\n",
      "\n",
      "       [[148, 188, 190],\n",
      "        [166, 186, 191],\n",
      "        [ 60,  67,  69],\n",
      "        ...,\n",
      "        [ 58,  58,  58],\n",
      "        [ 58,  58,  58],\n",
      "        [ 58,  58,  58]],\n",
      "\n",
      "       [[136, 171, 173],\n",
      "        [ 65,  74,  81],\n",
      "        [ 42,  40,  41],\n",
      "        ...,\n",
      "        [ 58,  58,  58],\n",
      "        [ 58,  58,  58],\n",
      "        [ 58,  58,  58]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 35,  29,  31],\n",
      "        [ 22,  23,  38],\n",
      "        [ 27,  29,  40],\n",
      "        ...,\n",
      "        [ 54,  54,  54],\n",
      "        [ 55,  55,  55],\n",
      "        [ 54,  54,  54]],\n",
      "\n",
      "       [[ 44,  39,  37],\n",
      "        [ 22,  25,  36],\n",
      "        [ 24,  27,  37],\n",
      "        ...,\n",
      "        [ 55,  55,  55],\n",
      "        [ 54,  54,  54],\n",
      "        [ 54,  54,  54]],\n",
      "\n",
      "       [[ 56,  50,  44],\n",
      "        [ 23,  25,  34],\n",
      "        [ 13,  16,  26],\n",
      "        ...,\n",
      "        [ 55,  55,  55],\n",
      "        [ 54,  54,  54],\n",
      "        [ 54,  54,  54]]], dtype=uint8), array([[[ 19,  23,  64],\n",
      "        [ 12,  19,  38],\n",
      "        [ 14,  23,  31],\n",
      "        ...,\n",
      "        [ 12,  12,  12],\n",
      "        [ 12,  12,  12],\n",
      "        [ 12,  12,  12]],\n",
      "\n",
      "       [[ 15,  17,  56],\n",
      "        [  9,  14,  31],\n",
      "        [ 15,  20,  26],\n",
      "        ...,\n",
      "        [ 12,  12,  12],\n",
      "        [ 12,  12,  12],\n",
      "        [ 12,  12,  12]],\n",
      "\n",
      "       [[ 14,  18,  55],\n",
      "        [ 10,  17,  33],\n",
      "        [ 15,  23,  27],\n",
      "        ...,\n",
      "        [ 12,  12,  12],\n",
      "        [ 12,  12,  12],\n",
      "        [ 12,  12,  12]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[194, 181, 159],\n",
      "        [192, 181, 153],\n",
      "        [186, 176, 145],\n",
      "        ...,\n",
      "        [ 97,  97,  97],\n",
      "        [ 98,  98,  98],\n",
      "        [ 98,  98,  98]],\n",
      "\n",
      "       [[192, 179, 157],\n",
      "        [186, 175, 148],\n",
      "        [181, 171, 140],\n",
      "        ...,\n",
      "        [ 97,  97,  97],\n",
      "        [ 98,  98,  98],\n",
      "        [ 98,  98,  98]],\n",
      "\n",
      "       [[191, 178, 156],\n",
      "        [182, 171, 144],\n",
      "        [177, 168, 137],\n",
      "        ...,\n",
      "        [ 98,  98,  98],\n",
      "        [ 98,  98,  98],\n",
      "        [ 98,  98,  98]]], dtype=uint8)]\n"
     ]
    }
   ],
   "source": [
    "import os.path as osp\n",
    "\n",
    "import cv2\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "import torch.hub\n",
    "import os\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torchsummary import summary\n",
    "from visualize.grad_cam import BackPropagation, GradCAM,GuidedBackPropagation\n",
    "\n",
    "faceCascade = cv2.CascadeClassifier('./visualize/haarcascade_frontalface_default.xml')\n",
    "shape = (48,48)\n",
    "classes = [\n",
    "    'Angry',\n",
    "    'Disgust',\n",
    "    'Fear',\n",
    "    'Happy',\n",
    "    'Sad',\n",
    "    'Surprised',\n",
    "    'Neutral'\n",
    "]\n",
    "\n",
    "def preprocess(image_path):\n",
    "    transform_test = transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    image = cv2.imread(image_path)\n",
    "    faces = faceCascade.detectMultiScale(\n",
    "        image,\n",
    "        scaleFactor=1.1,\n",
    "        minNeighbors=5,\n",
    "        minSize=(1, 1),\n",
    "        flags=cv2.CASCADE_SCALE_IMAGE\n",
    "    )\n",
    "\n",
    "    if len(faces) == 0:\n",
    "        print('no face found')\n",
    "        face = cv2.resize(image, shape)\n",
    "    else:\n",
    "        (x, y, w, h) = faces[0]\n",
    "        face = image[y:y + h, x:x + w]\n",
    "        face = cv2.resize(face, shape)\n",
    "\n",
    "    img = Image.fromarray(face).convert('L')\n",
    "    inputs = transform_test(img)\n",
    "    return inputs, face\n",
    "\n",
    "\n",
    "def get_gradient_image(gradient):\n",
    "    gradient = gradient.cpu().numpy().transpose(1, 2, 0)\n",
    "    gradient -= gradient.min()\n",
    "    gradient /= gradient.max()\n",
    "    gradient *= 255.0\n",
    "    return np.uint8(gradient)\n",
    "\n",
    "\n",
    "def get_gradcam_image(gcam, raw_image, paper_cmap=False):\n",
    "    gcam = gcam.cpu().numpy()\n",
    "    cmap = cm.jet_r(gcam)[..., :3] * 255.0\n",
    "    if paper_cmap:\n",
    "        alpha = gcam[..., None]\n",
    "        gcam = alpha * cmap + (1 - alpha) * raw_image\n",
    "    else:\n",
    "        gcam = (cmap.astype(np.float) + raw_image.astype(np.float)) / 2\n",
    "    return np.uint8(gcam)\n",
    "\n",
    "\n",
    "def guided_backprop(images, model_name):\n",
    "\n",
    "    for i, image in enumerate(images):\n",
    "        target, raw_image = preprocess(image['path'])\n",
    "        image['image'] = target\n",
    "        image['raw_image'] = raw_image\n",
    "\n",
    "    net = model.Model(num_classes=len(classes))\n",
    "    checkpoint = torch.load(os.path.join('../trained', model_name), map_location=torch.device('cpu'))\n",
    "    net.load_state_dict(checkpoint['net'])\n",
    "    net.eval()\n",
    "    summary(net, (1, shape[0], shape[1]))\n",
    "\n",
    "    result_images = []\n",
    "    for index, image in enumerate(images):\n",
    "        img = torch.stack([image['image']])\n",
    "        bp = BackPropagation(model=net)\n",
    "        probs, ids = bp.forward(img)\n",
    "        gcam = GradCAM(model=net)\n",
    "        _ = gcam.forward(img)\n",
    "\n",
    "        gbp = GuidedBackPropagation(model=net)\n",
    "        _ = gbp.forward(img)\n",
    "\n",
    "        # Guided Backpropagation\n",
    "        actual_emotion = ids[:,0]\n",
    "        gbp.backward(ids=actual_emotion.reshape(1,1))\n",
    "        gradients = gbp.generate()\n",
    "\n",
    "        # Grad-CAM\n",
    "        gcam.backward(ids=actual_emotion.reshape(1,1))\n",
    "        regions = gcam.generate(target_layer='last_conv')\n",
    "\n",
    "        # Get Images\n",
    "        label_image = np.zeros((shape[0],65, 3), np.uint8)\n",
    "        cv2.putText(label_image, classes[actual_emotion.data], (5, 25), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "        prob_image = np.zeros((shape[0],60,3), np.uint8)\n",
    "        cv2.putText(prob_image, '%.1f%%' % (probs.data[:,0] * 100), (5, 25), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "        guided_bpg_image = get_gradient_image(gradients[0])\n",
    "        guided_bpg_image = cv2.merge((guided_bpg_image, guided_bpg_image, guided_bpg_image))\n",
    "\n",
    "        grad_cam_image = get_gradcam_image(gcam=regions[0, 0],raw_image=image['raw_image'])\n",
    "\n",
    "        guided_gradcam_image = get_gradient_image(torch.mul(regions, gradients)[0])\n",
    "        guided_gradcam_image = cv2.merge((guided_gradcam_image, guided_gradcam_image, guided_gradcam_image))\n",
    "\n",
    "        img = cv2.hconcat([image['raw_image'],label_image,prob_image,guided_bpg_image,grad_cam_image,guided_gradcam_image])\n",
    "        result_images.append(img)\n",
    "        print(image['path'],classes[actual_emotion.data], probs.data[:,0] * 100)\n",
    "\n",
    "    cv2.imwrite('../test/test.jpg',cv2.resize(cv2.vconcat(result_images), None, fx=2,fy=2))\n",
    "    print(result_images)\n",
    "\n",
    "def main():\n",
    "    guided_backprop(\n",
    "        images=[\n",
    "            {'path': '../test/angry.jpg'},\n",
    "            {'path': '../test/happy.jpg'},\n",
    "            {'path': '../test/sad.jpg'},\n",
    "            {'path': '../test/surprised.jpg'},\n",
    "        ],\n",
    "        model_name='private_model_233_66.t7'\n",
    "    )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
